{"cells":[{"cell_type":"markdown","source":["# Intro\n","\n","This notebook reads all bronze tables from Mythic via uploader folder, cleans tables and writes tables to silver."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"fdd0948f-2e24-4d1d-8aa5-56d72858da8f"},{"cell_type":"markdown","source":["\n","## Change History\n","\n","<style>\n","  table {margin-left: 0 !important;}\n","</style>\n","\n","| Date    | Author | Description |\n","| :-------- | :------- | :------- | \n","|2025-07-01 | Mclain R |  Created Date|"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e711b89f-7c89-4ce1-970a-7fbda31352ad"},{"cell_type":"markdown","source":["# Code"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c0903670-4caa-4826-94fc-d8d36d5cff85"},{"cell_type":"markdown","source":["## Imports\n","\n","###### notebookutils\n","- **mssparkutils**: A utility module in Microsoft Fabric that provides functions for handling file operations, secrets, and other notebook-related tasks within the Spark environment.\n","\n","###### pyspark.sql.functions\n","- **col**: A function used to reference a DataFrame column in PySpark expressions, typically for transformations or filtering.\n","- **F**: A common alias for importing PySpark SQL functions, allowing access to various built-in functions (e.g., F.lit(), F.when(), etc.) for DataFrame transformations.\n","\n","###### python\n","- **re**: The regular expressions module used for pattern matching, text parsing, and string manipulation in Python."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d97e94d3-5ce6-466f-98b5-9cc7ff75bcc3"},{"cell_type":"code","source":["from notebookutils import mssparkutils\n","from pyspark.sql.functions import col\n","import re\n","# import pyspark.sql.functions as F\n","from pyspark.sql import functions as F\n","from pyspark.sql.types import StringType"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ac62b1aa-09a3-4556-9373-5581cfe992f9"},{"cell_type":"markdown","source":["## Define Parameters\n","- none\n","\n","Note: the following is a parameter cell and will be interpreted by Pipelines as such."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"433ce2dc-5d79-4200-bbad-c9940e537a63"},{"cell_type":"markdown","source":["## Reused Functions"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"33b30c21-71aa-421f-8e74-e05fda77a8ea"},{"cell_type":"code","source":["# Function to format phone numbers for HubSpot\n","def format_phone_for_hubspot(phone_str):\n","    \"\"\"\n","    Format phone number to HubSpot E.164 format (+1XXXXXXXXXX for US numbers)\n","    Handles the specific formats found in your data:\n","    - '+1 2538619993' -> '+12538619993' \n","    - '(813) 927-2957' -> '+18139272957'\n","    - '+1 15127912247' -> '+15127912247' (fixes the extra 1)\n","    \"\"\"\n","    if phone_str is None or phone_str == \"\":\n","        return None\n","    \n","    cleaned = str(phone_str).strip()\n","    \n","    # Handle the error case: +1 1XXXXXXXXXX (12 digits total)\n","    # This appears to be +1 + extra 1 + 10 digit number\n","    if re.match(r'^\\+1 1\\d{10}$', cleaned):\n","        digits = re.sub(r'\\D', '', cleaned)\n","        return f\"+{digits[1:]}\"  # Remove the extra '1' after country code\n","    \n","    # Handle normal +1 XXXXXXXXXX (with space) -> remove space\n","    if re.match(r'^\\+1 \\d{10}$', cleaned):\n","        return cleaned.replace(' ', '')\n","    \n","    # Handle +1XXXXXXXXXX (already correct format)\n","    if re.match(r'^\\+1\\d{10}$', cleaned):\n","        return cleaned\n","    \n","    # Handle (XXX) XXX-XXXX format -> convert to +1XXXXXXXXXX\n","    if re.match(r'^\\(\\d{3}\\) \\d{3}-\\d{4}$', cleaned):\n","        digits = re.sub(r'\\D', '', cleaned)\n","        return f\"+1{digits}\"\n","    \n","    # Fallback: extract digits and format\n","    digits_only = re.sub(r'\\D', '', cleaned)\n","    if len(digits_only) == 10:\n","        return f\"+1{digits_only}\"\n","    elif len(digits_only) == 11 and digits_only.startswith('1'):\n","        return f\"+{digits_only}\"\n","    elif len(digits_only) == 12 and digits_only.startswith('11'):\n","        # Handle the 12-digit error case in digit-only form\n","        return f\"+{digits_only[1:]}\"\n","    else:\n","        # Return None for any unhandleable formats\n","        return None\n","\n","# Register UDF\n","format_phone_udf = F.udf(format_phone_for_hubspot, StringType())"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"451249d1-265d-42d4-b2b4-b133a3944f3b"},{"cell_type":"code","source":["#Function to format emails for HubSpot\n","def format_email_for_hubspot(email_str):\n","    \"\"\"\n","    Replace @ally.com with @dealerbeyond.ally.com for HubSpot integration\n","    \"\"\"\n","    if email_str is None or email_str == \"\":\n","        return None\n","    \n","    email_cleaned = str(email_str).strip()\n","    \n","    # Replace @ally.com with @dealerbeyond.ally.com\n","    if email_cleaned.endswith(\"@ally.com\"):\n","        return email_cleaned.replace(\"@ally.com\", \"@dealerbeyond.ally.com\")\n","    else:\n","        return email_cleaned\n","\n","# Register UDF\n","format_email_udf = F.udf(format_email_for_hubspot, StringType())"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"afbf190d-1d7a-40c6-ac2a-8e5cbf251cbf"},{"cell_type":"markdown","source":["## Define Fields\n","\n","- **workspace_name**: name of workspace\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ecc34593-6440-45cb-b7c3-cacf1b8e406c"},{"cell_type":"code","source":["import sempy\n","import sempy.fabric as fabric\n","\n","# Get the current workspace ID\n","workspace_id = fabric.get_workspace_id()\n","print(f\"Workspace ID: {workspace_id}\")\n","\n","# Get the workspace name from the workspace ID\n","workspace_name = fabric.resolve_workspace_name(workspace_id)\n","print(f\"Workspace Name: {workspace_name}\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2d211f5a-66c8-455b-a244-451e05cc284f"},{"cell_type":"markdown","source":["## Process Data"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"06082564-a5c2-4f32-af81-416ce2490e28"},{"cell_type":"code","source":["# Base path containing the folders\n","base_path = f\"abfss://{workspace_name}@onelake.dfs.fabric.microsoft.com/bronze_lakehouse.Lakehouse/Tables\"\n","\n","# List all items in the base path\n","items = mssparkutils.fs.ls(base_path)\n","\n","# Get Table paths for additional fields tables\n","table_paths = [item.path for item in items if item.isDir and item.name.startswith('icrm_names_for_leads')]\n","\n","# Process each table\n","for table_path in table_paths:\n","    table_name = table_path.split('/')[-1]\n","\n","    try:\n","        # Read Delta Table from the folder\n","        df = spark.read.format(\"delta\").load(table_path)\n","        display(f\"Processing: {table_name}\")\n","\n","        # Specify the exact phone number columns to format\n","        all_phone_columns = [\n","            'f_i_dir_of_sales_mobile',\n","            'f_i_sr_dir_of_sales_mobile', \n","            'regional_growth_leader_1_mobile',\n","            'regional_growth_leader_2_mobile',\n","            'p_c_sr_director_of_sales_mobile',\n","            'p_c_director_of_sales_mobile',\n","            'p_c_account_manager_mobile'\n","        ]\n","\n","        # Specify the email columns and their HubSpot duplicates\n","        email_columns_mapping = {\n","            'f_i_dir_of_sales_email': 'f_i_dir_of_sales_hubspot_email',\n","            'f_i_sr_dir_of_sales_email': 'f_i_sr_dir_of_sales_hubspot_email',\n","            'regional_growth_leader_1_email': 'regional_growth_leader_1_hubspot_email',\n","            'regional_growth_leader_2_email': 'regional_growth_leader_2_hubspot_email',\n","            'p_c_sr_director_of_sales_email': 'p_c_sr_director_of_sales_hubspot_email',\n","            'p_c_director_of_sales_email': 'p_c_director_of_sales_hubspot_email',\n","            'p_c_account_manager_email': 'p_c_account_manager_hubspot_email'\n","        }\n","        \n","        # Only process columns that actually exist in the dataframe\n","        phone_columns = [col for col in all_phone_columns if col in df.columns]\n","        email_columns = {orig: new for orig, new in email_columns_mapping.items() if orig in df.columns}\n","\n","        # Apply phone formatting to identified columns\n","        for phone_col in phone_columns:\n","            df = df.withColumn(phone_col, format_phone_udf(F.col(phone_col)))\n","\n","        # Create HubSpot email columns with @dealerbeyond.ally.com domain\n","        for original_email_col, hubspot_email_col in email_columns.items():\n","            df = df.withColumn(hubspot_email_col, format_email_udf(F.col(original_email_col)))\n","        \n","        display(df.head(10))\n","\n","        # Write to Delta table\n","        delta_table_path = f\"abfss://{workspace_name}@onelake.dfs.fabric.microsoft.com/silver_lakehouse.Lakehouse/Tables/{table_name}\"\n","        df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").save(delta_table_path)\n","\n","        display(f\"Successfully processed {table_name} with phone formatting and HubSpot email columns\")\n","\n","    except Exception as e:\n","        display(f\"Skipping {table_name}: {str(e)}\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"36993b05-43d4-41d5-95ae-4f610db4689e"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"d504714c-cf53-49a6-9c26-27f921eee20a"},{"id":"9629524c-13f0-4a9a-affe-58ab1c2f5dbe"}],"default_lakehouse":"d504714c-cf53-49a6-9c26-27f921eee20a","default_lakehouse_name":"silver_lakehouse","default_lakehouse_workspace_id":"fef507b4-c0af-40cc-9309-b183e59c0547"}}},"nbformat":4,"nbformat_minor":5}