{"cells":[{"cell_type":"markdown","source":["# Intro\n","\n","This notebook reads all bronze tables from Mythic via uploader folder, cleans tables and writes tables to silver."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"fdd0948f-2e24-4d1d-8aa5-56d72858da8f"},{"cell_type":"markdown","source":["\n","## Change History\n","\n","<style>\n","  table {margin-left: 0 !important;}\n","</style>\n","\n","| Date    | Author | Description |\n","| :-------- | :------- | :------- | \n","|2024-10-14 | Mclain R |  Created Date|\n","|2025-01-16 | Mclain R |  Changes to reflect new process|\n","|2025-01-23 | Mclain R |  Use email instead of contact_id|\n","|2025-02-26 | Mclain R |  Adjust code so dcrm file contains contact_role field|"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e711b89f-7c89-4ce1-970a-7fbda31352ad"},{"cell_type":"markdown","source":["# Code"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c0903670-4caa-4826-94fc-d8d36d5cff85"},{"cell_type":"markdown","source":["## Imports\n","\n","###### notebookutils\n","- **mssparkutils**: A utility module in Microsoft Fabric that provides functions for handling file operations, secrets, and other notebook-related tasks within the Spark environment.\n","\n","###### pyspark.sql.functions\n","- **col**: A function used to reference a DataFrame column in PySpark expressions, typically for transformations or filtering.\n","- **F**: A common alias for importing PySpark SQL functions, allowing access to various built-in functions (e.g., F.lit(), F.when(), etc.) for DataFrame transformations.\n","\n","###### python\n","- **re**: The regular expressions module used for pattern matching, text parsing, and string manipulation in Python."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d97e94d3-5ce6-466f-98b5-9cc7ff75bcc3"},{"cell_type":"code","source":["from notebookutils import mssparkutils\n","from pyspark.sql.functions import col\n","import re\n","# import pyspark.sql.functions as F\n","from pyspark.sql import functions as F"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ac62b1aa-09a3-4556-9373-5581cfe992f9"},{"cell_type":"markdown","source":["## Define Parameters\n","- none\n","\n","Note: the following is a parameter cell and will be interpreted by Pipelines as such."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"433ce2dc-5d79-4200-bbad-c9940e537a63"},{"cell_type":"markdown","source":["## Reused Functions\n","- none"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"33b30c21-71aa-421f-8e74-e05fda77a8ea"},{"cell_type":"markdown","source":["## Define Fields\n","\n","- **workspace_name**: name of workspace\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ecc34593-6440-45cb-b7c3-cacf1b8e406c"},{"cell_type":"code","source":["import sempy\n","import sempy.fabric as fabric\n","\n","# Get the current workspace ID\n","workspace_id = fabric.get_workspace_id()\n","print(f\"Workspace ID: {workspace_id}\")\n","\n","# Get the workspace name from the workspace ID\n","workspace_name = fabric.resolve_workspace_name(workspace_id)\n","print(f\"Workspace Name: {workspace_name}\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2d211f5a-66c8-455b-a244-451e05cc284f"},{"cell_type":"markdown","source":["## Process Data"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"06082564-a5c2-4f32-af81-416ce2490e28"},{"cell_type":"code","source":["# Base path containing the folders\n","base_path = f\"abfss://{workspace_name}@onelake.dfs.fabric.microsoft.com/bronze_lakehouse.Lakehouse/Tables\"\n","\n","# List all items in the base path\n","items = mssparkutils.fs.ls(base_path)\n","\n","# Get Table paths for additonal fields tables\n","table_paths = [item.path for item in items if item.isDir and (item.name.startswith('nucleus__icrm_contacts') or item.name.startswith('nucleus__dcrm_contacts'))]\n","\n","# Process each table\n","for table_path in table_paths:\n","    # Read Delta Tables from the folder\n","    df = spark.read.format(\"delta\").load(table_path)\n","\n","    display(table_path.split('/')[-1])\n","\n","    if table_path.split('/')[-1] == 'nucleus__dcrm_contacts':\n","\n","        # Split the 'contact_role' into an array where roles are separated by \";\"\n","        df = df.withColumn(\"roles_array\", F.split(F.col(\"contact_role\"), \"; \"))\n","\n","        # Explode the 'roles_array' into multiple rows\n","        df = df.withColumn(\"contact_role_single\", F.explode(F.col(\"roles_array\")))\n","\n","        # Define the job title based on the exploded single role\n","        df = df.withColumn(\n","            \"job_title\",\n","            F.when(\n","                F.col(\"contact_role_single\").isin([\"CEO\", \"CFO\", \"CFO/Controller\", \"Comptroller\", \"Controller\", \"Dealer Principal\", \"Owner\", \"President\", \"Owner/Principal\"]), \"Owner/Principal\"\n","            ).when(\n","                F.col(\"contact_role_single\").isin([\"Ally Systems Authorizer\", \"Assist Service Manager\", \"Branch Manager\", \"Business Manager\", \"Fixed Operations Manager\", \"Garage Insurance Decision Maker\", \"General Manager\", \"General Sales Manager\", \"GM Warranty Manager\", \"Inventory Manager\", \"Manager\", \"Office Manager\", \"Operations Director\", \"Treasurer\", \"Vice President\"]), \"General Manager\"\n","            ).when(\n","                F.col(\"contact_role_single\").isin([\"Credit Admin Contact\", \"DS-Decision Maker\", \"DS-Gate Keeper\", \"F&I Manager\", \"Finance Director\", \"GAP/Aftermarket Cancellation\", \"Used Car F&I Manager\", \"Warranty Administrator\", \"Finance Manager\"]), \"Finance Manager\"\n","            ).when(\n","                F.col(\"contact_role_single\").isin([\"Fleet/Commercial Admin\", \"Fleet/Commercial Manager\", \"Fleet/Commercial Sales\", \"New Car Manager\", \"Sales Manager\", \"Sales Staff\", \"SmartAuction Buyer\", \"SmartAuction Seller\", \"SmartAuction User\", \"Used Car Manager\"]), \"Sales Manager\"\n","            ).when(\n","                F.col(\"contact_role_single\") == \"Other\", \"Other\"\n","            ).when(\n","                F.col(\"contact_role_single\").isin([\"No Longer Employed\", \"No Longer Employeed\"]), \"No Longer Employeed\"\n","            ).when(\n","                F.col(\"contact_role_single\").isin([\"CIO\", \"Claims IT Manager\", \"Clearlane Leads\", \"Compliance Officer\", \"COVID-Communications\", \"Held Offering Contact\", \"Human Resources Manager\", \"Internet Manager\", \"Marketing Manager\", \"Office Staff\", \"Parts Manager\", \"Service Advisor\", \"Service Director\", \"Service Manager\", \"Shop Foreman\", \"Targeted Messaging Contact\", \"Title Clerk\", \"Never Targeted\"]), \"Never Targeted\"\n","            ).otherwise(\"Unknown\")\n","        )\n","\n","        # Drop the 'roles_array' and 'contact_role_single' column after use\n","        df = df.drop(\"roles_array\")\n","        df = df.drop(\"contact_role_single\")\n","    \n","    else:\n","\n","        # Split the 'contact_title' into an array where roles are separated by \";\"\n","        df = df.withColumn(\"titles_array\", F.split(F.col(\"contact_title\"), \"; \"))\n","\n","        # Explode the 'titles_array' into multiple rows\n","        df = df.withColumn(\"contact_title_single\", F.explode(F.col(\"titles_array\")))\n","\n","        # Define the job title based on the exploded single title\n","        df = df.withColumn(\n","            \"job_title\",\n","            F.when(\n","                F.col(\"contact_title_single\").isin([\"CEO\", \"CFO\", \"CFO/Controller\", \"Comptroller\", \"Controller\", \"Dealer Principal\", \"Owner\", \"President\", \"Owner/Principal\"]), \"Owner/Principal\"\n","            ).when(\n","                F.col(\"contact_title_single\").isin([\"Ally Systems Authorizer\", \"Assist Service Manager\", \"Branch Manager\", \"Business Manager\", \"Fixed Operations Manager\", \"Garage Insurance Decision Maker\", \"General Manager\", \"General Sales Manager\", \"GM Warranty Manager\", \"Inventory Manager\", \"Manager\", \"Office Manager\", \"Operations Director\", \"Treasurer\", \"Vice President\"]), \"General Manager\"\n","            ).when(\n","                F.col(\"contact_title_single\").isin([\"Credit Admin Contact\", \"DS-Decision Maker\", \"DS-Gate Keeper\", \"F&I Manager\", \"Finance Director\", \"GAP/Aftermarket Cancellation\", \"Used Car F&I Manager\", \"Warranty Administrator\", \"Finance Manager\"]), \"Finance Manager\"\n","            ).when(\n","                F.col(\"contact_title_single\").isin([\"Fleet/Commercial Admin\", \"Fleet/Commercial Manager\", \"Fleet/Commercial Sales\", \"New Car Manager\", \"Sales Manager\", \"Sales Staff\", \"SmartAuction Buyer\", \"SmartAuction Seller\", \"SmartAuction User\", \"Used Car Manager\"]), \"Sales Manager\"\n","            ).when(\n","                F.col(\"contact_title_single\") == \"Other\", \"Other\"\n","            ).when(\n","                F.col(\"contact_title_single\").isin([\"No Longer Employed\", \"No Longer Employeed\"]), \"No Longer Employeed\"\n","            ).when(\n","                F.col(\"contact_title_single\").isin([\"CIO\", \"Claims IT Manager\", \"Clearlane Leads\", \"Compliance Officer\", \"COVID-Communications\", \"Held Offering Contact\", \"Human Resources Manager\", \"Internet Manager\", \"Marketing Manager\", \"Office Staff\", \"Parts Manager\", \"Service Advisor\", \"Service Director\", \"Service Manager\", \"Shop Foreman\", \"Targeted Messaging Contact\", \"Title Clerk\", \"Never Targeted\"]), \"Never Targeted\"\n","            ).otherwise(\"Unknown\")\n","        )\n","\n","        # Drop the 'titles_array' and 'contact_title_single' column after use\n","        df = df.drop(\"titles_array\")\n","        df = df.drop(\"contact_title_single\")\n","\n","    display(df.head(10))\n","\n","    # Write to Delta table\n","    delta_table_path = f\"abfss://{workspace_name}@onelake.dfs.fabric.microsoft.com/silver_lakehouse.Lakehouse/Tables/\" + table_path.split('/')[-1]\n","    df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").save(delta_table_path)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"36993b05-43d4-41d5-95ae-4f610db4689e"},{"cell_type":"code","source":["# Combine both tables and write to one combined table\n","df_combined = spark.sql(\"\"\"\n","SELECT DISTINCT\n","    job_title,\n","    account_id,\n","    uniqueaccountid,\n","    email\n","FROM silver_lakehouse.nucleus__dcrm_contacts\n","WHERE job_title is not null\n","    AND email like '%@%'\n","\n","UNION\n","\n","SELECT DISTINCT\n","    job_title,\n","    account_id,\n","    uniqueaccountid,\n","    email\n","FROM silver_lakehouse.nucleus__icrm_contacts\n","WHERE job_title is not null\n","    AND email like '%@%'\n","\"\"\")\n","\n","# Write to Delta table\n","delta_table_path = f\"abfss://{workspace_name}@onelake.dfs.fabric.microsoft.com/silver_lakehouse.Lakehouse/Tables/nucleus__combined_contacts\"\n","df_combined.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").save(delta_table_path)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f0c3948e-d0e9-4032-86fe-9b92389d606a"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"d504714c-cf53-49a6-9c26-27f921eee20a"},{"id":"9629524c-13f0-4a9a-affe-58ab1c2f5dbe"}],"default_lakehouse":"d504714c-cf53-49a6-9c26-27f921eee20a","default_lakehouse_name":"silver_lakehouse","default_lakehouse_workspace_id":"fef507b4-c0af-40cc-9309-b183e59c0547"}}},"nbformat":4,"nbformat_minor":5}